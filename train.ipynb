{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import re\n",
    "file_path = './data/TAF/train/2022-09-04.csv'\n",
    "fuser_df = pd.read_csv(file_path)\n",
    "nan_s = fuser_df.isnull().sum()\n",
    "print(nan_s[nan_s> 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "taf_pattern = re.compile(\n",
    "    r'^(?:PART\\s+\\d+(?:\\s+OF(?:\\s+\\d+)?)?\\s+)?'                           # Optional PART X OF Y\n",
    "    r'(?:TAF\\s+)*'                                               # Allow multiple TAF prefixes\n",
    "    r'(?P<amended>(AMD)\\s+)?'                                 # Optional AMD flag for amended reports\n",
    "    r'(?P<corection>(COR)\\s+)?'                                 # Optional COR flag for corrected reports\n",
    "    r'(?P<station>\\w{4})(?:\\s+\\w{4})?\\s+'                                      # ICAO station code\n",
    "    r'(?P<issue_datetime>\\d{6}Z\\s+)?'                             # Optional issue date and time\n",
    "    r'(?P<validity>(?P<valid_start_day>\\d{2})(?P<valid_start_hour>\\d{2})/'\n",
    "    r'(?P<valid_end_day>\\d{2})(?P<valid_end_hour>\\d{2}))\\s+'      # Validity period\n",
    "    r'(?P<wind>(VRB|\\d{3})\\d{2,3}(G\\d{2,3})?[/|?]?(KT|MPS|KMH)?)?\\s*' # Wind information\n",
    "    r'(?P<visibility>\\d{4}|CAVOK|9999|////|[0-9]+SM)?\\s*'         # Visibility\n",
    "\n",
    "    # Weather with optional intensity prefix (+ or -) and non-greedy match\n",
    "    r'(?P<weather>(\\+|-)?[A-Z]{2,6})?\\s+'                         # Weather phenomena with optional intensity, followed by whitespace\n",
    "    r'(?P<clouds>((FEW|SCT|BKN|OVC|NSC|VV|NCD|CLR|SKC|///)\\d{3}(CB)?\\s*)*)' # Cloud layers\n",
    "    r'(?P<qnh>QNH\\d{4}(INS|HPA)?)?\\s*'                            # QNH (altimeter setting) in inches or hPa\n",
    "    r'(?P<variable_wind>WND\\s+\\d{3}V\\d{3})?\\s*'                   # Variable wind direction\n",
    "\n",
    "    # Max/Min Temperature capture with optional minus sign for temperatures\n",
    "    r'(?P<max_temp>TX(?P<max_temp_value>M?\\d{2})/'                # Max temperature with optional minus sign\n",
    "    r'(?P<max_temp_day>\\d{2})(?P<max_temp_hour>\\d{2})Z\\s*)?'      \n",
    "    r'(?P<min_temp>TN(?P<min_temp_value>M?\\d{2})/'                # Min temperature with optional minus sign\n",
    "    r'(?P<min_temp_day>\\d{2})(?P<min_temp_hour>\\d{2})Z\\s*)?'      \n",
    "    r'(?P<probability>PROB(?P<prob_value>\\d{2}))?\\s*'             # Probability\n",
    "\n",
    "    # Capture everything else in additional_sections\n",
    "    r'(?P<additional_sections>.*?)$'                               # Capture all remaining parts as additional sections\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates_in_report(report):\n",
    "    words = report.split()\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            seen.add(word)\n",
    "            result.append(word)\n",
    "    return ' '.join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validity(data):\n",
    "    # Ensure date_time is a datetime object in UTC for calculations\n",
    "    base_date = pd.to_datetime(data['date_time'], utc=True)\n",
    "\n",
    "    # Construct valid_start_date\n",
    "    start_day = int(data['valid_start_day'])\n",
    "    start_hour = int(data['valid_start_hour'])\n",
    "    valid_start_date = base_date.replace(day=start_day, hour=start_hour)\n",
    "\n",
    "    # If the start day is before the base date's day (new month rollover), adjust the month and year\n",
    "    if valid_start_date < base_date:\n",
    "        valid_start_date += timedelta(days=30)  # Adjust depending on month rollover logic\n",
    "    if valid_start_date < base_date:\n",
    "        valid_start_date += relativedelta(months=1)\n",
    "        \n",
    "    # Construct valid_end_date\n",
    "    end_day = int(data['valid_end_day'])\n",
    "    end_hour = int(data['valid_end_hour'])\n",
    "    \n",
    "    if end_hour == 24:\n",
    "        end_hour = 0\n",
    "        end_day += 1\n",
    "        \n",
    "    valid_end_date = base_date.replace(day=end_day, hour=end_hour)\n",
    "\n",
    "    # Handle cases where end day may be in the following month\n",
    "    if valid_end_date < valid_start_date:\n",
    "        valid_end_date += timedelta(days=30)  # Adjust based on month rollover logic\n",
    "\n",
    "    # Add results back to the data dictionary\n",
    "    data['valid_start_date'] = valid_start_date\n",
    "    data['valid_end_date'] = valid_end_date\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wind(data):\n",
    "    \"\"\"Processes the wind field, extracts direction and speed, and converts units to knots if necessary.\"\"\"\n",
    "    # Extract the wind field\n",
    "    wind_str = data.get('wind')\n",
    "    if wind_str is None:\n",
    "        # Set default values for missing wind data\n",
    "        data['wind_direction'] = 999  # 999 indicates variable or missing direction\n",
    "        data['wind_speed_kt'] = None\n",
    "        data['wind_gust_kt'] = None\n",
    "        return data\n",
    "\n",
    "    # Use regex to match and extract components of the wind string\n",
    "    match = re.match(r'^(VRB|\\d{3})?([/?]?\\d{2,3})(G[/?]?\\d{2,3})?(KT|MPS|KMH)?$', wind_str)\n",
    "    if not match:\n",
    "        # Set defaults for unrecognized wind patterns\n",
    "        data['wind_direction'] = 999\n",
    "        data['wind_speed_kt'] = None\n",
    "        data['wind_gust_kt'] = None\n",
    "        return data\n",
    "\n",
    "    # Extract matched components\n",
    "    direction, speed, gust, unit = match.groups()\n",
    "\n",
    "    # Set direction to 999 if variable (VRB) or missing\n",
    "    direction = 999 if direction == 'VRB' or direction is None else int(direction)\n",
    "    speed = int(speed) if speed and speed.isdigit() else None\n",
    "    gust = int(gust[1:]) if gust and gust[1:].isdigit() else None\n",
    "\n",
    "    # Convert speeds to knots (KT) if necessary\n",
    "    if unit == 'MPS':\n",
    "        speed = round(speed * 1.94384) if speed else None  # MPS to KT\n",
    "        gust = round(gust * 1.94384) if gust else None\n",
    "    elif unit == 'KMH':\n",
    "        speed = round(speed * 0.539957) if speed else None  # KMH to KT\n",
    "        gust = round(gust * 0.539957) if gust else None\n",
    "\n",
    "    # Update data dictionary with processed values\n",
    "    data['wind_direction'] = direction\n",
    "    data['wind_speed_kt'] = speed\n",
    "    data['wind_gust_kt'] = gust\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_mapping = {\n",
    "    \"DZ\": 1,  # Drizzle\n",
    "    \"RA\": 3,  # Rain\n",
    "    \"SN\": 5,  # Snow\n",
    "    \"SG\": 2,  # Snow Grains\n",
    "    \"IC\": 2,  # Ice Crystals\n",
    "    \"PL\": 3,  # Ice Pellets\n",
    "    \"GR\": 6,  # Hail\n",
    "    \"GS\": 4,  # Small Hail or Snow Pellets\n",
    "    \"UP\": 2,  # Unknown Precipitation\n",
    "    \"BR\": 1,  # Mist\n",
    "    \"FG\": 3,  # Fog\n",
    "    \"FU\": 4,  # Smoke\n",
    "    \"VA\": 5,  # Volcanic Ash\n",
    "    \"DU\": 3,  # Dust\n",
    "    \"SA\": 4,  # Sand\n",
    "    \"HZ\": 2,  # Haze\n",
    "    \"PY\": 3,  # Spray\n",
    "    \"PO\": 4,  # Dust/Sand Whirls\n",
    "    \"SQ\": 5,  # Squall\n",
    "    \"FC\": 6,  # Funnel Cloud (Tornado/Waterspout)\n",
    "    \"SS\": 6,  # Sandstorm\n",
    "    \"DS\": 6,  # Duststorm\n",
    "    \"SH\": 4,  # Showers\n",
    "    \"TS\": 5,  # Thunderstorm\n",
    "    \"FZ\": 5   # Freezing\n",
    "}\n",
    "\n",
    "# Intensity multipliers\n",
    "intensity_mapping = {\n",
    "    \"-\": 0.5,  # Light intensity\n",
    "    \"+\": 1.5,  # Heavy intensity\n",
    "    None: 1.0  # Standard intensity\n",
    "}\n",
    "\n",
    "def process_weather(data):\n",
    "    \"\"\"Processes the 'weather' field in the data dictionary to assign a score based on intensity and type.\"\"\"\n",
    "    weather_str = data.get('weather', None)\n",
    "    if not weather_str:\n",
    "        data['weather_score'] = 0  # Default score if no weather data is present\n",
    "        return data\n",
    "\n",
    "    # Extract intensity and weather type\n",
    "    match = re.match(r'^(\\+|-)?([A-Z]{2,6})$', weather_str)\n",
    "    if not match:\n",
    "        data['weather_score'] = 0  # Default score for unrecognized patterns\n",
    "        return data\n",
    "\n",
    "    # Get the intensity and weather code\n",
    "    intensity, weather_code = match.groups()\n",
    "\n",
    "    # Calculate score based on weather code and intensity\n",
    "    base_score = weather_mapping.get(weather_code, 0)  # Get base score for weather type\n",
    "    multiplier = intensity_mapping.get(intensity, 1.0)  # Apply multiplier based on intensity\n",
    "    score = base_score * multiplier\n",
    "\n",
    "    # Update data dictionary with calculated weather score\n",
    "    data['weather_score'] = score\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_cover_dict = {\n",
    "    \"SKC\": 0,  # Sky Clear\n",
    "    \"CLR\": 0,  # Clear\n",
    "    \"NSC\": 0,  # No Significant Clouds\n",
    "    \"NCD\": 0,  # No Cloud Detected\n",
    "    \"FEW\": 1,  # Few (1/8 to 2/8 sky cover)\n",
    "    \"SCT\": 3,  # Scattered (3/8 to 4/8 sky cover)\n",
    "    \"BKN\": 5,  # Broken (5/8 to 7/8 sky cover)\n",
    "    \"OVC\": 8,  # Overcast (8/8 sky cover)\n",
    "    \"VV\": 9    # Vertical Visibility (obscured sky, treated as full overcast)\n",
    "}\n",
    "\n",
    "def parse_cloud_layers(cloud_layers):\n",
    "    \"\"\"Convert cloud layer codes to structured data for modeling.\"\"\"\n",
    "    parsed_layers = []\n",
    "    for layer in cloud_layers:\n",
    "        # Match cloud layer code, altitude, and CB flag if present\n",
    "        match = re.match(r\"([A-Z]{3})(\\d{3})?(CB)?\", layer)\n",
    "        if match:\n",
    "            cloud_code, altitude, cumulonimbus = match.groups()\n",
    "            sky_cover = cloud_cover_dict.get(cloud_code, None)  # Get sky cover value\n",
    "            altitude_ft = int(altitude) * 100 if altitude else None  # Convert altitude to feet if present\n",
    "            cb_flag = 1 if cumulonimbus else 0  # Cumulonimbus flag (1 for CB, 0 otherwise)\n",
    "\n",
    "            # Append the structured cloud data\n",
    "            parsed_layers.append({\n",
    "                \"sky_cover\": sky_cover,           # Numerical sky cover level\n",
    "                \"altitude_ft\": altitude_ft,       # Altitude in feet\n",
    "                \"cumulonimbus\": cb_flag           # Cumulonimbus presence (1 or 0)\n",
    "            })\n",
    "    return parsed_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qnh(data):\n",
    "    \"\"\"\n",
    "    Process the 'qnh' field to a unified unit in HPA.\n",
    "    If the unit is in inches (INS), convert it to HPA.\n",
    "    If the unit is missing, set it as None.\n",
    "    \"\"\"\n",
    "    qnh_str = data.get('qnh', None)\n",
    "    \n",
    "    if qnh_str is None:\n",
    "        data['qnh_hpa'] = None\n",
    "        return data\n",
    "\n",
    "    # Match QNH format\n",
    "    match = re.match(r'QNH(\\d{4})(INS|HPA)?', qnh_str)\n",
    "    if match:\n",
    "        qnh_value, unit = match.groups()\n",
    "        qnh_value = int(qnh_value)\n",
    "\n",
    "        # Convert INS to HPA if necessary\n",
    "        if unit == \"INS\":\n",
    "            qnh_value = round(qnh_value * 33.8639)  # 1 inHg = 33.8639 hPa\n",
    "        data['qnh_hpa'] = qnh_value\n",
    "    else:\n",
    "        data['qnh_hpa'] = None  # Default for unrecognized patterns\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_variable_wind(data):\n",
    "    \"\"\"\n",
    "    Process the 'variable_wind' field to extract the variable wind directions.\n",
    "    If the wind is variable, extract starting and ending directions in degrees.\n",
    "    If the format is unrecognized or missing, set values to None.\n",
    "    \"\"\"\n",
    "    variable_wind_str = data.get('variable_wind', None)\n",
    "    \n",
    "    if variable_wind_str is None:\n",
    "        data['variable_wind_from'] = None\n",
    "        data['variable_wind_to'] = None\n",
    "        return data\n",
    "\n",
    "    # Match variable wind format WND XXXVYYY\n",
    "    match = re.match(r'WND\\s+(\\d{3})V(\\d{3})', variable_wind_str)\n",
    "    if match:\n",
    "        from_dir, to_dir = match.groups()\n",
    "        data['variable_wind_from'] = int(from_dir)\n",
    "        data['variable_wind_to'] = int(to_dir)\n",
    "    else:\n",
    "        # If the format is not recognized, set to None\n",
    "        data['variable_wind_from'] = None\n",
    "        data['variable_wind_to'] = None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_temp_to_datetime(data):\n",
    "    \"\"\"\n",
    "    Converts max_temp_day/max_temp_hour and min_temp_day/min_temp_hour to full UTC datetime.\n",
    "    Adjusts times set to 24:00 to 00:00 of the following day.\n",
    "    \"\"\"\n",
    "    # Get base date from data['date_time']\n",
    "    base_date = data.get('date_time', None)\n",
    "    if base_date is None:\n",
    "        data['max_temperature_time'] = None\n",
    "        data['min_temperature_time'] = None\n",
    "        return data\n",
    "\n",
    "    # Helper function to handle day/hour adjustments\n",
    "    def calculate_temperature_time(day, hour):\n",
    "        temp_time = datetime(\n",
    "            year=base_date.year,\n",
    "            month=base_date.month,\n",
    "            day=int(day),\n",
    "            hour=0 if hour == 24 else hour,\n",
    "            tzinfo=base_date.tzinfo\n",
    "        )\n",
    "        # Shift to next day if hour was 24\n",
    "        if hour == 24:\n",
    "            temp_time += timedelta(days=1)\n",
    "        # Handle month transitions if necessary\n",
    "        if temp_time < base_date:\n",
    "            temp_time += relativedelta(months=1)\n",
    "        tempDate = calculate_temperature_dates(base_date, end_hour, end_hour)    \n",
    "        valid_end_date = base_date.replace(year=tempDate.year, \n",
    "                                       day=tempDate.day, \n",
    "                                       hour=tempDate.hour, \n",
    "                                       minute=tempDate.minute, \n",
    "                                       second=tempDate.second)\n",
    "        return temp_time\n",
    "\n",
    "    # Process max temperature datetime\n",
    "    max_day = data.get('max_temp_day')\n",
    "    max_hour = int(data.get('max_temp_hour')) if data.get('max_temp_hour') else None\n",
    "    data['max_temperature_time'] = calculate_temperature_time(max_day, max_hour) if max_day and max_hour is not None else None\n",
    "\n",
    "    # Process min temperature datetime\n",
    "    min_day = data.get('min_temp_day')\n",
    "    min_hour = int(data.get('min_temp_hour')) if data.get('min_temp_hour') else None\n",
    "    data['min_temperature_time'] = calculate_temperature_time(min_day, min_hour) if min_day and min_hour is not None else None\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_probability(data):\n",
    "    prob_str = data.get('probability', None)\n",
    "\n",
    "    if prob_str and 'PROB' in prob_str:\n",
    "        data['probability'] = round(float(data['prob_value']) / 100, 2)\n",
    "        data['has_prob'] = True\n",
    "    else:\n",
    "        data['probability'] = 0.9\n",
    "        data['has_prob'] = False\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse TAF report \n",
    "def parse_taf_block(date_time, line):\n",
    "    \"\"\"Parse a full TAF block into its components.\"\"\"\n",
    "    \n",
    "    # Regex pattern to match main TAF components across multiple lines \n",
    "    match = taf_pattern.match(line)\n",
    "\n",
    "    if match:\n",
    "        data = match.groupdict()\n",
    "\n",
    "        # Convert `date_time` to UTC format\n",
    "        try:\n",
    "            utc_date = datetime.strptime(date_time, \"%Y/%m/%d %H:%M\").replace(tzinfo=timezone.utc)\n",
    "            data['date_time'] = utc_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            data['date_time'] = pd.to_datetime(data['date_time'], utc=True)\n",
    "        except ValueError as e:\n",
    "            data['date_time'] = None\n",
    "        \n",
    "        # Amended handling\n",
    "        data['amended'] = True if data.get('amended') == 'AMD' else False\n",
    "\n",
    "        # corection handling\n",
    "        data['corection'] = True if data.get('corection') == 'COR' else False\n",
    "        \n",
    "        # validity date handling\n",
    "        data = process_validity(data)\n",
    "\n",
    "        data = process_wind(data)\n",
    "\n",
    "        visibility = data.get('visibility')\n",
    "        if visibility == \"CAVOK\":\n",
    "            data['visibility_meters'] = 10000  # Convention for CAVOK\n",
    "        elif visibility and \"SM\" in visibility:\n",
    "\n",
    "            visibility_miles = float(visibility.replace(\"SM\", \"\"))\n",
    "            data['visibility_meters'] = int(visibility_miles * 1609.34)\n",
    "        elif visibility and visibility.isdigit():\n",
    "            data['visibility_meters'] = int(visibility)\n",
    "        else:\n",
    "            data['visibility_meters'] = None\n",
    "\n",
    "        max_temp_value = data.get('max_temp_value', None)\n",
    "        if max_temp_value is not None:\n",
    "            value = re.search(r'\\d+', max_temp_value)\n",
    "            data['max_temp_value'] = int(max_temp_value) if 'M' not in max_temp_value else 0 - int(value.group())\n",
    "            \n",
    "\n",
    "        \n",
    "        min_temp_value = data.get('min_temp_value', None)\n",
    "        if min_temp_value is not None:\n",
    "            value = re.search(r'\\d+', min_temp_value)\n",
    "            data['min_temp_value'] = int(min_temp_value) if 'M' not in min_temp_value else 0 - int(value.group())\n",
    "        \n",
    "        data = process_weather(data)\n",
    "\n",
    "        clouds = data.get('clouds')\n",
    "        data['cloud_layers'] = parse_cloud_layers(clouds.strip().split()) if clouds else []\n",
    "\n",
    "        data = process_qnh(data)\n",
    "        \n",
    "        data = process_variable_wind(data)\n",
    "\n",
    "        data = convert_temp_to_datetime(data)\n",
    "        data = process_probability(data)\n",
    "        fields_to_drop = ['valid_start_day', 'valid_start_hour', 'valid_end_hour', 'valid_end_day',\n",
    "                           'wind', 'clouds', 'qnh', 'variable_wind', 'max_temp_day', 'max_temp_hour'\n",
    "                           , 'min_temp_day', 'min_temp_hour', 'max_temp', 'min_temp', 'validity', \n",
    "                           'prob_value', 'visibility'] \n",
    "        for field in fields_to_drop:\n",
    "            if field in data:\n",
    "                del data[field]\n",
    "        return data\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jaosn/finalProject/data/TAF/train/taf.20220901.00Z.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "data_entries = []\n",
    "current_date_time = None\n",
    "current_report_lines = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue  # Skip empty lines\n",
    "    # Check if the line contains a date-time\n",
    "    date_time_match = re.match(r'\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}', line)\n",
    "    if date_time_match:\n",
    "        # If thereâ€™s an accumulated report, parse it\n",
    "        if current_report_lines:\n",
    "            full_report = ' '.join(current_report_lines)\n",
    "            # Split multiple TAF reports within the same block\n",
    "            taf_reports = re.split(r'=\\s*', full_report)\n",
    "            for report in taf_reports:\n",
    "                report = report.strip()\n",
    "                if report:\n",
    "                    report = remove_duplicates_in_report(report)\n",
    "                    parsed_data = parse_taf_block(current_date_time, report)\n",
    "                    if parsed_data:\n",
    "                        data_entries.append(parsed_data)\n",
    "            current_report_lines = []\n",
    "        current_date_time = date_time_match.group()\n",
    "    else:\n",
    "        # Continue accumulating lines for the current report\n",
    "        current_report_lines.append(line)\n",
    "\n",
    "# Process the last report if any\n",
    "if current_report_lines:\n",
    "    full_report = ' '.join(current_report_lines)\n",
    "    taf_reports = re.split(r'=\\s*', full_report)\n",
    "    for report in taf_reports:\n",
    "        report = report.strip()\n",
    "        if report:\n",
    "            report = remove_duplicates_in_report(report)\n",
    "            parsed_data = parse_taf_block(current_date_time, report)\n",
    "            if parsed_data:\n",
    "                data_entries.append(parsed_data)\n",
    "df =pd.DataFrame(data_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      amended  corection station issue_datetime weather  max_temp_value  \\\n",
      "0       False      False    ZGKL       012104Z     None            32.0   \n",
      "1       False      False    ZGNN       012108Z     None            35.0   \n",
      "2       False      False    ZGOW       012101Z     None            35.0   \n",
      "3       False      False    ZGSZ       012120Z     None            34.0   \n",
      "4       False      False    ZLXY       012107Z       BR             NaN   \n",
      "...       ...        ...     ...            ...     ...             ...   \n",
      "1076    False      False    TLPL       012300Z     None             NaN   \n",
      "1077    False      False    TLPC       012300Z     None             NaN   \n",
      "1078    False      False    KNBG           None    None             NaN   \n",
      "1079    False      False    KNHK           None     SKC             NaN   \n",
      "1080    False      False    KNQX           None    None             NaN   \n",
      "\n",
      "      min_temp_value  probability  \\\n",
      "0               20.0          0.9   \n",
      "1               26.0          0.9   \n",
      "2               25.0          0.9   \n",
      "3               28.0          0.9   \n",
      "4                NaN          0.9   \n",
      "...              ...          ...   \n",
      "1076             NaN          0.3   \n",
      "1077             NaN          0.3   \n",
      "1078             NaN          0.9   \n",
      "1079             NaN          0.9   \n",
      "1080             NaN          0.9   \n",
      "\n",
      "                                    additional_sections  \\\n",
      "0                                                         \n",
      "1                                                         \n",
      "2                                                         \n",
      "3                                                         \n",
      "4                             NSC TX28/0208Z TN19/0222Z   \n",
      "...                                                 ...   \n",
      "1076                 TEMPO 0209/0218 5000 SHRA FEW015CB   \n",
      "1077                 TEMPO 0209/0218 5000 SHRA FEW015CB   \n",
      "1078  FM020300 VRB03KT 4800 BR FEW035 QNH2990INS FM0...   \n",
      "1079  BECMG 0214/0216 11007KT FEW060 FEW110 SCT280 Q...   \n",
      "1080  FM020700 11010KT VCSH QNK2995INS AUTOMATED SEN...   \n",
      "\n",
      "                     date_time  ... wind_gust_kt visibility_meters  \\\n",
      "0    2022-09-01 00:00:00+00:00  ...          NaN            7000.0   \n",
      "1    2022-09-01 00:00:00+00:00  ...          NaN            7000.0   \n",
      "2    2022-09-01 00:00:00+00:00  ...          NaN            6000.0   \n",
      "3    2022-09-01 00:00:00+00:00  ...          NaN            6000.0   \n",
      "4    2022-09-01 00:00:00+00:00  ...          NaN            3000.0   \n",
      "...                        ...  ...          ...               ...   \n",
      "1076 2022-09-01 00:07:00+00:00  ...          NaN            9999.0   \n",
      "1077 2022-09-01 00:07:00+00:00  ...          NaN            9999.0   \n",
      "1078 2022-09-01 23:08:00+00:00  ...          NaN            9999.0   \n",
      "1079 2022-09-01 23:08:00+00:00  ...          NaN            9999.0   \n",
      "1080 2022-09-01 23:08:00+00:00  ...          NaN            9999.0   \n",
      "\n",
      "      weather_score                                       cloud_layers  \\\n",
      "0               0.0  [{'sky_cover': 3, 'altitude_ft': 5000, 'cumulo...   \n",
      "1               0.0  [{'sky_cover': 3, 'altitude_ft': 3300, 'cumulo...   \n",
      "2               0.0  [{'sky_cover': 1, 'altitude_ft': 2000, 'cumulo...   \n",
      "3               0.0  [{'sky_cover': 3, 'altitude_ft': 2600, 'cumulo...   \n",
      "4               1.0                                                 []   \n",
      "...             ...                                                ...   \n",
      "1076            0.0  [{'sky_cover': 3, 'altitude_ft': 2500, 'cumulo...   \n",
      "1077            0.0  [{'sky_cover': 3, 'altitude_ft': 2500, 'cumulo...   \n",
      "1078            0.0  [{'sky_cover': 3, 'altitude_ft': 4000, 'cumulo...   \n",
      "1079            0.0                                                 []   \n",
      "1080            0.0  [{'sky_cover': 1, 'altitude_ft': 2500, 'cumulo...   \n",
      "\n",
      "       qnh_hpa  variable_wind_from  variable_wind_to  \\\n",
      "0          NaN                 NaN               NaN   \n",
      "1          NaN                 NaN               NaN   \n",
      "2          NaN                 NaN               NaN   \n",
      "3          NaN                 NaN               NaN   \n",
      "4          NaN                 NaN               NaN   \n",
      "...        ...                 ...               ...   \n",
      "1076       NaN                 NaN               NaN   \n",
      "1077       NaN                 NaN               NaN   \n",
      "1078  101084.0                 NaN               NaN   \n",
      "1079  101389.0                 NaN               NaN   \n",
      "1080  101389.0                 NaN               NaN   \n",
      "\n",
      "          max_temperature_time      min_temperature_time  has_prob  \n",
      "0    2022-09-02 08:00:00+00:00 2022-09-02 22:00:00+00:00     False  \n",
      "1    2022-09-02 07:00:00+00:00 2022-09-02 22:00:00+00:00     False  \n",
      "2    2022-09-02 06:00:00+00:00 2022-09-02 22:00:00+00:00     False  \n",
      "3    2022-09-02 06:00:00+00:00 2022-09-02 22:00:00+00:00     False  \n",
      "4                          NaT                       NaT     False  \n",
      "...                        ...                       ...       ...  \n",
      "1076                       NaT                       NaT      True  \n",
      "1077                       NaT                       NaT      True  \n",
      "1078                       NaT                       NaT     False  \n",
      "1079                       NaT                       NaT     False  \n",
      "1080                       NaT                       NaT     False  \n",
      "\n",
      "[1081 rows x 24 columns]\n",
      "amended                                bool\n",
      "corection                              bool\n",
      "station                              object\n",
      "issue_datetime                       object\n",
      "weather                              object\n",
      "max_temp_value                      float64\n",
      "min_temp_value                      float64\n",
      "probability                         float64\n",
      "additional_sections                  object\n",
      "date_time               datetime64[ns, UTC]\n",
      "valid_start_date        datetime64[ns, UTC]\n",
      "valid_end_date          datetime64[ns, UTC]\n",
      "wind_direction                        int64\n",
      "wind_speed_kt                         int64\n",
      "wind_gust_kt                        float64\n",
      "visibility_meters                   float64\n",
      "weather_score                       float64\n",
      "cloud_layers                         object\n",
      "qnh_hpa                             float64\n",
      "variable_wind_from                  float64\n",
      "variable_wind_to                    float64\n",
      "max_temperature_time    datetime64[ns, UTC]\n",
      "min_temperature_time    datetime64[ns, UTC]\n",
      "has_prob                               bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amended                                bool\n",
      "corection                              bool\n",
      "station                              object\n",
      "issue_datetime                       object\n",
      "weather                              object\n",
      "max_temp_value                      float64\n",
      "min_temp_value                      float64\n",
      "probability                         float64\n",
      "additional_sections                  object\n",
      "date_time               datetime64[ns, UTC]\n",
      "valid_start_date        datetime64[ns, UTC]\n",
      "valid_end_date          datetime64[ns, UTC]\n",
      "has_wind                              int64\n",
      "wind_is_variable                      int64\n",
      "wind_direction                        int64\n",
      "wind_speed_kt                       float64\n",
      "wind_gust_kt                        float64\n",
      "visibility_meters                   float64\n",
      "weather_score                       float64\n",
      "cloud_layers                         object\n",
      "qnh_hpa                             float64\n",
      "variable_wind_from                   object\n",
      "variable_wind_to                     object\n",
      "max_temperature_time    datetime64[ns, UTC]\n",
      "min_temperature_time    datetime64[ns, UTC]\n",
      "has_prob                               bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import fetchData\n",
    "taf_data = fetchData.load_data( \n",
    "    data_type=\"TAF\", \n",
    "    dataset_purpose=\"test\",  \n",
    "    file_name=\"taf.20220925.00Z\"\n",
    ")\n",
    "print(taf_data.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
