{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse METAR report \n",
    "def parse_metar_line(date_time, line):\n",
    "    \"\"\"Parse a single METAR report line into its components, including optional AUTO.\"\"\"\n",
    "    metar_pattern = re.compile(\n",
    "        r'^(?P<station>[A-Z]{4})\\s+'\n",
    "        r'(?P<datetime>\\d{2}\\d{4}Z)\\s+'\n",
    "        r'(?P<auto>AUTO\\s+)?'\n",
    "        r'(?P<wind>\\d{3}\\d{2}(G\\d{2})?(KT|MPS|KMH))?\\s*'\n",
    "        r'(?P<visibility>\\d{4}(SM|NDV)?|CAVOK|////)?\\s*'\n",
    "        r'(?P<clouds>(///\\d{3}///|FEW|SCT|BKN|OVC|NSC|VV|///)\\d{0,3}[A-Z]{0,3}\\s*)*'\n",
    "        r'(?P<temperature>M?\\d{2})/(?P<dewpoint>M?\\d{2}|//)\\s+'\n",
    "        r'Q(?P<pressure>\\d{4})\\s*'\n",
    "        r'(?P<remarks>.+)?$'\n",
    "    )\n",
    "    \n",
    "    match = metar_pattern.match(line)\n",
    "    if match:\n",
    "        data = match.groupdict()\n",
    "        \n",
    "        # Process the clouds group to handle multiple cloud layers\n",
    "        clouds = data.get('clouds')\n",
    "        if clouds:\n",
    "            data['clouds'] = clouds.strip().split()\n",
    "        else:\n",
    "            data['clouds'] = None\n",
    "        \n",
    "        data['date_time'] = date_time\n",
    "        # Handle optional fields\n",
    "        data['auto'] = data['auto'].strip() if data['auto'] else None\n",
    "        data['remarks'] = data['remarks'].strip() if data['remarks'] else None\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Parse TAF report \n",
    "def parse_taf_block(block):\n",
    "    \"\"\"Parse a full TAF block into its components.\"\"\"\n",
    "    # Regex pattern to match main TAF components across multiple lines\n",
    "    taf_pattern = re.compile(\n",
    "        r'(?P<station>TAF \\w{4})\\s+'                     # Station identifier (TAF + ICAO code)\n",
    "        r'(?P<datetime>\\d{6}Z)\\s+'                       # Date and time of issuance\n",
    "        r'(?P<validity>\\d{4}/\\d{4})\\s+'                  # Validity period\n",
    "        r'(?P<wind>(\\d{5}(KT|MPS|KMH)|VRB\\d{2}(KT|MPS|KMH)?)?)\\s*'  # Wind information\n",
    "        r'(?P<visibility>CAVOK|\\d{4})?\\s*'               # Visibility, including CAVOK\n",
    "        r'(?P<clouds>(SCT|BKN|FEW|NSC|OVC|NSC|VV)\\d{3}[A-Z]{0,3})?\\s*' # Cloud information\n",
    "        r'(?P<temp_dewpoint>(TX|TN)\\d{2}/\\d{4}Z)?\\s*'    # Max/min temperature forecast\n",
    "        \n",
    "        # Additional forecasts as separate groups\n",
    "        r'(?P<probability>(PROB\\d{2}\\s+\\d{4}/\\d{4}\\s+.*)*)'     # Probability forecasts (e.g., PROB30)\n",
    "        r'(?P<temporary>(TEMPO\\s+\\d{4}/\\d{4}\\s+.*)*)'        # Temporary forecasts\n",
    "        r'(?P<becoming>(BECMG\\s+\\d{4}/\\d{4}\\s+.*)*)'        # Becoming forecasts\n",
    "        r'(?P<from_forecasts>(FM\\d{6}\\s+.*)*)'                       # From forecasts\n",
    "    )\n",
    "    \n",
    "    match = taf_pattern.search(block)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return None\n",
    "\n",
    "# CWAM\n",
    "def get_dataset(f):\n",
    "    data_entries = []\n",
    "    for forecast_time in f['Deviation Probability']:\n",
    "        for flight_level in f[f'Deviation Probability/{forecast_time}']:\n",
    "            for contour in f[f'Deviation Probability/{forecast_time}/{flight_level}']:\n",
    "                for threshold in f[f'Deviation Probability/{forecast_time}/{flight_level}/{contour}']:\n",
    "                    for polygon in f[f'Deviation Probability/{forecast_time}/{flight_level}/{contour}/{threshold}']:\n",
    "                        # Construct the full path for the dataset\n",
    "                        dataset_name = f'Deviation Probability/{forecast_time}/{flight_level}/{contour}/{threshold}/{polygon}'\n",
    "                        \n",
    "                        dataset = f[dataset_name][:]\n",
    "                        latitudes, longitudes = dataset[0], dataset[1]\n",
    "                        \n",
    "                        fcst = forecast_time\n",
    "                        flvl = flight_level\n",
    "                        trsh = threshold\n",
    "                        poly = polygon\n",
    "\n",
    "                        data_entries.append({\n",
    "                            \"Forecast Time (FCST)\" : fcst,\n",
    "                            \"Flight Level (FLVL)\" : flvl,\n",
    "                            \"Threshold (TRSH)\" : trsh,\n",
    "                            \"Polygon Number (POLY)\" : poly,\n",
    "                            \"Latitudes\" : latitudes,\n",
    "                            \"Longitudes\" : longitudes\n",
    "                        })\n",
    "    return pd.DataFrame(data_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, dataset_purpose, path_level=None, month=None, day=None, file_name=None, base_dir=None):\n",
    "    \"\"\"\n",
    "    Loads a data file from a specified path.\n",
    "    \n",
    "    Parameters\n",
    "    - data_type (str): Data type, e.g., \"CWAM\", \"FUSER\", \"METAR\", \"TAF\".\n",
    "    - dataset_purpose (str): \"train\" or \"test\", indicating training or testing data.\n",
    "    - path_level (str): CWAM or METAR part_X, e.g., \"part_1\".\n",
    "    - month (str): Month, e.g., \"09\".\n",
    "    - day (str): Day, e.g., \"29\".\n",
    "    - file_name (str): Filename (without extension or type-specific suffix), e.g., \"2022_09_29_20_00_GMT.Forecast\".\n",
    "    - base_dir (str): Root directory of the data, e.g., \"/home/finalProject/data\".\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame, HDF5 file object, or string content based on file type.\n",
    "    \"\"\"\n",
    "\n",
    "    base_dir = \"/home/jaosn/finalProject/data\" if not base_dir else base_dir\n",
    "    # Specify file extensions\n",
    "    file_ext = file_extension[data_type]\n",
    "    \n",
    "    # Build the file path based on data type\n",
    "    if data_type == \"CWAM\":\n",
    "        # CWAM Path: data/CWAM/test/part_X/MM/DD\n",
    "        if not (path_level and month and day):\n",
    "            raise ValueError(\"CWAM data requires path_level, month, and day\")\n",
    "        path = os.path.join(base_dir, data_type, dataset_purpose, path_level, month, day)\n",
    "        # CWAM files use a specific naming convention\n",
    "        file_path = os.path.join(path, f\"{file_name}.h5.CWAM.h5\")\n",
    "        \n",
    "    elif data_type == \"FUSER\":\n",
    "        # FUSER Path: data/FUSER/train/KXXX/\n",
    "        if not path_level:\n",
    "            raise ValueError(\"FUSER data requires fuser_type\")\n",
    "        path = os.path.join(base_dir, data_type, dataset_purpose, path_level)\n",
    "        file_path = os.path.join(path, f\"{file_name}.csv\")\n",
    "    \n",
    "    elif data_type in [\"METAR\", \"TAF\"]:\n",
    "        # METAR and TAF Paths: data/METAR/train/part_X/\n",
    "        if dataset_purpose == \"train\" and not path_level:\n",
    "            raise ValueError(f\"{data_type} data requires path_level\")\n",
    "        if dataset_purpose == \"train\":\n",
    "            path = os.path.join(base_dir, data_type, dataset_purpose, path_level)\n",
    "        else:\n",
    "            path = os.path.join(base_dir, data_type, dataset_purpose)\n",
    "        file_path = os.path.join(path, f\"{file_name}.txt\")\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data type: {data_type}\")\n",
    "\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    # Load file based on file type\n",
    "    if data_type == \"FUSER\":\n",
    "        def extract_file_type(file_name):\n",
    "            pattern = r'^(?P<airport>\\w+)' \\\n",
    "                      r'_(?P<date_range>\\d{4}-\\d{2}-\\d{2}(_\\d{4}-\\d{2}-\\d{2})?)' \\\n",
    "                      r'\\.(?P<file_type>\\w+)_data_set$'\n",
    "              \n",
    "            match = re.match(pattern, file_name)\n",
    "            \n",
    "            if match:\n",
    "                file_type = match.group('file_type')\n",
    "                return file_type\n",
    "            else:\n",
    "                return None\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        file_type = extract_file_type(file_name)\n",
    "        df['file_type'] = file_type\n",
    "        return df\n",
    "    elif data_type in [\"METAR\", \"TAF\"]:\n",
    "        if data_type == \"METAR\":\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                lines = [line.strip() for line in lines if line.strip()]\n",
    "                data_entries = []\n",
    "                date_time = None  # To keep track of the current date and time\n",
    "\n",
    "                for line in lines:\n",
    "                    # Check if the line is a date line\n",
    "                    if re.match(r'\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}', line):\n",
    "                        date_time = line  # Store the date and time\n",
    "                    elif date_time:  # If we have a date_time, process the METAR line\n",
    "                        parsed_data = parse_metar_line(date_time, line)\n",
    "                        if parsed_data:\n",
    "                            data_entries.append(parsed_data)\n",
    "                        date_time = None \n",
    "            return pd.DataFrame(data_entries)\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "                lines = file.readlines()\n",
    "    \n",
    "            data_entries = []\n",
    "            buffer = \"\"  # To accumulate lines for a single TAF block\n",
    "\n",
    "            i = 0\n",
    "            while i < len(lines):\n",
    "                line = lines[i].strip()\n",
    "                \n",
    "                # If the line starts with a date, treat it as a new TAF report block\n",
    "                date_match = re.match(r'\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}', line)\n",
    "                if date_match:\n",
    "                    if buffer:  # Parse the previous buffer before moving to the next date block\n",
    "                        parsed_data = parse_taf_block(buffer)\n",
    "                        if parsed_data:\n",
    "                            parsed_data[\"Date and Time\"] = date_time  # Associate with the last stored date\n",
    "                            data_entries.append(parsed_data)\n",
    "                        buffer = \"\"  # Clear buffer for the new TAF block\n",
    "                    date_time = date_match.group()  # Update date_time to the new block's date\n",
    "\n",
    "                # Continue adding lines to the buffer for the current TAF block\n",
    "                if line.startswith(\"TAF\") or buffer:\n",
    "                    buffer += line + \" \"\n",
    "\n",
    "                # Move to the next line\n",
    "                i += 1\n",
    "\n",
    "            # Parse the last block in the buffer after the loop ends\n",
    "            if buffer:\n",
    "                parsed_data = parse_taf_block(buffer)\n",
    "                if parsed_data:\n",
    "                    parsed_data[\"Date and Time\"] = date_time\n",
    "                    data_entries.append(parsed_data)\n",
    "\n",
    "            # Convert the list of dictionaries to a DataFrame\n",
    "            return pd.DataFrame(data_entries)\n",
    "    elif data_type == \"CWAM\":\n",
    "        with h5py.File(file_path, 'r') as file:  # Load HDF5 data\n",
    "            \n",
    "            return get_dataset(file)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {file_ext}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwam_data = load_data( \n",
    "    data_type=\"CWAM\", \n",
    "    dataset_purpose=\"train\", \n",
    "    path_level=\"part_1_220901_220924\", \n",
    "    month=\"09\", \n",
    "    day=\"01\", \n",
    "    file_name=\"2022_09_01_20_00_GMT.Forecast\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Forecast Time (FCST) Flight Level (FLVL) Threshold (TRSH)  \\\n",
      "0                   FCST000             FLVL250          TRSH060   \n",
      "1                   FCST000             FLVL250          TRSH060   \n",
      "2                   FCST000             FLVL250          TRSH060   \n",
      "3                   FCST000             FLVL250          TRSH060   \n",
      "4                   FCST000             FLVL250          TRSH060   \n",
      "...                     ...                 ...              ...   \n",
      "104484              FCST120             FLVL450          TRSH080   \n",
      "104485              FCST120             FLVL450          TRSH080   \n",
      "104486              FCST120             FLVL450          TRSH080   \n",
      "104487              FCST120             FLVL450          TRSH080   \n",
      "104488              FCST120             FLVL450          TRSH080   \n",
      "\n",
      "       Polygon Number (POLY)  \\\n",
      "0                   POLY0001   \n",
      "1                   POLY0002   \n",
      "2                   POLY0003   \n",
      "3                   POLY0004   \n",
      "4                   POLY0005   \n",
      "...                      ...   \n",
      "104484              POLY0007   \n",
      "104485              POLY0008   \n",
      "104486              POLY0009   \n",
      "104487              POLY0010   \n",
      "104488              POLY0011   \n",
      "\n",
      "                                                Latitudes  \\\n",
      "0       [22.47349, 22.461931, 22.456131, 22.450317, 22...   \n",
      "1       [23.82428, 23.82375, 23.823462, 23.82316, 23.8...   \n",
      "2       [23.934841, 23.935038, 23.935114, 23.935177, 2...   \n",
      "3       [22.827188, 22.815912, 22.810253, 22.80458, 22...   \n",
      "4       [22.66365, 22.651442, 22.645317, 22.63918, 22....   \n",
      "...                                                   ...   \n",
      "104484  [32.016056, 32.00316, 31.996683, 31.990194, 32...   \n",
      "104485  [32.15372, 32.140953, 32.169758, 32.24018, 32....   \n",
      "104486  [33.5222, 33.518787, 33.51705, 33.515305, 33.5...   \n",
      "104487  [32.36117, 32.34764, 32.340855, 32.33405, 32.3...   \n",
      "104488  [33.297306, 33.28531, 33.279285, 33.27325, 33....   \n",
      "\n",
      "                                               Longitudes  \n",
      "0       [-81.81963, -81.7427, -81.70423, -81.66577, -8...  \n",
      "1       [-97.29758, -97.21953, -97.180504, -97.14149, ...  \n",
      "2       [-98.31249, -98.23437, -98.195305, -98.15624, ...  \n",
      "3       [-82.24263, -82.16547, -82.126884, -82.08831, ...  \n",
      "4       [-80.92684, -80.84982, -80.81131, -80.772804, ...  \n",
      "...                                                   ...  \n",
      "104484  [-80.79678, -80.712685, -80.67064, -80.6286, -...  \n",
      "104485  [-80.98617, -80.901924, -80.85276, -80.83862, ...  \n",
      "104486  [-93.51351, -93.42732, -93.38424, -93.34115, -...  \n",
      "104487  [-79.98647, -79.902115, -79.85995, -79.81778, ...  \n",
      "104488  [-82.11523, -82.029816, -81.987114, -81.94442,...  \n",
      "\n",
      "[104489 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cwam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuser_data = load_data(\n",
    "    data_type=\"FUSER\", \n",
    "    dataset_purpose=\"train\", \n",
    "    path_level=\"KATL\", \n",
    "    file_name=\"KATL_2022-09-01.configs_data_set\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   airport_id        data_header src_addr           datis_time  \\\n",
      "0        KATL  AD ATL /OS DT0052  ATLATXA  2022-09-01 00:52:00   \n",
      "1        KATL  AD ATL /OS DX0152  ATLATXA  2022-09-01 01:53:00   \n",
      "2        KATL  AD ATL /OS DY0152  ATLATXA  2022-09-01 02:06:00   \n",
      "3        KATL  AD ATL /OS DZ0252  ATLATXA  2022-09-01 02:54:00   \n",
      "4        KATL  AD ATL /OS DN0252  ATLATXA  2022-09-01 03:32:00   \n",
      "5        KATL  AD ATL /OS DO0352  ATLATXA  2022-09-01 04:04:00   \n",
      "6        KATL  AD ATL /OS DP0352  ATLATXA  2022-09-01 04:06:00   \n",
      "7        KATL  AD ATL /OS DQ0452  ATLATXA  2022-09-01 04:54:00   \n",
      "8        KATL  AD ATL /OS DR0552  ATLATXA  2022-09-01 06:06:00   \n",
      "9        KATL  AD ATL /OS DS0652  ATLATXA  2022-09-01 06:53:00   \n",
      "10       KATL  AD ATL /OS DT0752  ATLATXA  2022-09-01 07:56:00   \n",
      "11       KATL  AD ATL /OS DU0752  ATLATXA  2022-09-01 08:15:00   \n",
      "12       KATL  AD ATL /OS DV0852  ATLATXA  2022-09-01 09:08:00   \n",
      "13       KATL  AD ATL /OS DW0852  ATLATXA  2022-09-01 09:38:00   \n",
      "14       KATL  AD ATL /OS DX0852  ATLATXA  2022-09-01 09:43:00   \n",
      "15       KATL  AD ATL /OS DY0952  ATLATXA  2022-09-01 09:54:00   \n",
      "16       KATL  AD ATL /OS DZ0952  ATLATXA  2022-09-01 10:03:00   \n",
      "17       KATL  AD ATL /OS DN0952  ATLATXA  2022-09-01 10:18:00   \n",
      "18       KATL  AD ATL /OS DO1052  ATLATXA  2022-09-01 10:55:00   \n",
      "19       KATL  AD ATL /OS DP1052  ATLATXA  2022-09-01 11:48:00   \n",
      "20       KATL  AD ATL /OS DQ1152  ATLATXA  2022-09-01 11:58:00   \n",
      "21       KATL  AD ATL /OS DR1152  ATLATXA  2022-09-01 12:15:00   \n",
      "22       KATL  AD ATL /OS DS1252  ATLATXA  2022-09-01 12:53:00   \n",
      "23       KATL  AD ATL /OS DT1352  ATLATXA  2022-09-01 13:52:00   \n",
      "24       KATL  AD ATL /OS DU1452  ATLATXA  2022-09-01 14:54:00   \n",
      "25       KATL  AD ATL /OS DV1552  ATLATXA  2022-09-01 15:53:00   \n",
      "26       KATL  AD ATL /OS DW1652  ATLATXA  2022-09-01 16:53:00   \n",
      "27       KATL  AD ATL /OS DX1752  ATLATXA  2022-09-01 17:53:00   \n",
      "28       KATL  AD ATL /OS DN1852  ATLATXA  2022-09-01 18:53:00   \n",
      "29       KATL  AD ATL /OS DO1952  ATLATXA  2022-09-01 19:53:00   \n",
      "30       KATL  AD ATL /OS DP2052  ATLATXA  2022-09-01 20:52:00   \n",
      "31       KATL  AD ATL /OS DQ2152  ATLATXA  2022-09-01 21:54:00   \n",
      "32       KATL  AD ATL /OS DR2252  ATLATXA  2022-09-01 22:53:00   \n",
      "33       KATL  AD ATL /OS DS2352  ATLATXA  2022-09-01 23:52:00   \n",
      "\n",
      "             start_time                                     weather_report  \\\n",
      "0   2022-09-01 00:52:00   30006KT 10SM FEW250 26/16 A2999 (TWO NINER NI...   \n",
      "1   2022-09-01 01:53:00   31009KT 10SM FEW250 25/16 A3001 (THREE ZERO Z...   \n",
      "2   2022-09-01 02:06:00   31009KT 10SM FEW250 25/16 A3001 (THREE ZERO Z...   \n",
      "3   2022-09-01 02:54:00   31006KT 10SM FEW060 FEW250 24/16 A3001 (THREE...   \n",
      "4   2022-09-01 03:32:00   31006KT 10SM FEW060 FEW250 24/16 A3001 (THREE...   \n",
      "5   2022-09-01 04:04:00   31005KT 10SM FEW060 FEW250 23/17 A3001 (THREE...   \n",
      "6   2022-09-01 04:06:00   31005KT 10SM FEW060 FEW250 23/17 A3001 (THREE...   \n",
      "7   2022-09-01 04:54:00   30004KT 10SM FEW060 23/17 A3000 (THREE ZERO Z...   \n",
      "8   2022-09-01 06:06:00   33004KT 10SM CLR 23/16 A3000 (THREE ZERO ZERO...   \n",
      "9   2022-09-01 06:53:00   00000KT 10SM CLR 22/17 A3000 (THREE ZERO ZERO...   \n",
      "10  2022-09-01 07:56:00   31003KT 10SM FEW049 22/17 A3001 (THREE ZERO Z...   \n",
      "11  2022-09-01 08:15:00   31003KT 10SM FEW049 22/17 A3001 (THREE ZERO Z...   \n",
      "12  2022-09-01 09:08:00   32004KT 10SM FEW050 21/17 A3001 (THREE ZERO Z...   \n",
      "13  2022-09-01 09:38:00   32004KT 10SM FEW050 21/17 A3001 (THREE ZERO Z...   \n",
      "14  2022-09-01 09:43:00   32004KT 10SM FEW050 21/17 A3001 (THREE ZERO Z...   \n",
      "15  2022-09-01 09:54:00   01006KT 10SM CLR 22/16 A3001 (THREE ZERO ZERO...   \n",
      "16  2022-09-01 10:03:00   01006KT 10SM CLR 22/16 A3001 (THREE ZERO ZERO...   \n",
      "17  2022-09-01 10:18:00   01006KT 10SM CLR 22/16 A3001 (THREE ZERO ZERO...   \n",
      "18  2022-09-01 10:55:00   35005KT 10SM FEW055 FEW080 21/16 A3002 (THREE...   \n",
      "19  2022-09-01 11:48:00   35005KT 10SM FEW055 FEW080 21/16 A3002 (THREE...   \n",
      "20  2022-09-01 11:58:00   04005KT 10SM FEW055 FEW080 FEW250 23/16 A3003...   \n",
      "21  2022-09-01 12:15:00   04005KT 10SM FEW055 FEW080 FEW250 23/16 A3003...   \n",
      "22  2022-09-01 12:53:00   08008KT 10SM FEW065 FEW250 24/17 A3004 (THREE...   \n",
      "23  2022-09-01 13:52:00   08007KT 10SM FEW070 26/18 A3005 (THREE ZERO Z...   \n",
      "24  2022-09-01 14:54:00   12004KT 10SM FEW003 FEW075 FEW250 28/19 A3007...   \n",
      "25  2022-09-01 15:53:00   15008KT 10SM FEW040 FEW080 FEW250 30/19 A3007...   \n",
      "26  2022-09-01 16:53:00   08007KT 10SM FEW046 SCT080 SCT250 31/21 A3006...   \n",
      "27  2022-09-01 17:53:00   VRB03KT 10SM SCT050 BKN080 BKN250 32/19 A3004...   \n",
      "28  2022-09-01 18:53:00   00000KT 10SM SCT055 SCT080 SCT250 32/19 A3001...   \n",
      "29  2022-09-01 19:53:00   16005KT 10SM SCT055 SCT080 SCT200 32/19 A2999...   \n",
      "30  2022-09-01 20:52:00   21005KT 10SM FEW055TCU SCT080 SCT200 32/19 A2...   \n",
      "31  2022-09-01 21:54:00   19005KT 10SM SCT055TCU SCT080 BKN200 32/20 A2...   \n",
      "32  2022-09-01 22:53:00   10006KT 10SM FEW048TCU SCT070 SCT200 31/21 A2...   \n",
      "33  2022-09-01 23:52:00   15007KT 10SM FEW048TCU FEW200 28/22 A2999 (TW...   \n",
      "\n",
      "   departure_runways arrival_runways timestamp_source_received  \\\n",
      "0           26L, 27R    26R, 27L, 28       2022-09-01 00:52:51   \n",
      "1           26L, 27R    26R, 27L, 28       2022-09-01 01:53:12   \n",
      "2           26L, 27R    26R, 27L, 28       2022-09-01 02:06:05   \n",
      "3           26L, 27R    26R, 27L, 28       2022-09-01 02:54:44   \n",
      "4           26L, 27R        26R, 27R       2022-09-01 03:32:39   \n",
      "5           26L, 27R        26R, 27R       2022-09-01 04:04:59   \n",
      "6           26L, 27R        26R, 27R       2022-09-01 04:06:20   \n",
      "7           26L, 27R        26R, 27R       2022-09-01 04:54:30   \n",
      "8           26L, 27R        26R, 27R       2022-09-01 06:06:50   \n",
      "9           26L, 27R        26R, 27R       2022-09-01 06:53:05   \n",
      "10          26L, 27R        26R, 27R       2022-09-01 07:56:17   \n",
      "11          26L, 27R        26R, 27R       2022-09-01 08:15:53   \n",
      "12          26L, 27R        26R, 27R       2022-09-01 09:08:44   \n",
      "13          26L, 27R        26R, 27R       2022-09-01 09:38:21   \n",
      "14          26L, 27R    26R, 27L, 28       2022-09-01 09:43:51   \n",
      "15          26L, 27R    26R, 27L, 28       2022-09-01 09:54:52   \n",
      "16          26L, 27R    26R, 27L, 28       2022-09-01 10:03:39   \n",
      "17            8R, 9L      10, 8L, 9R       2022-09-01 10:18:30   \n",
      "18            8R, 9L      10, 8L, 9R       2022-09-01 10:55:26   \n",
      "19            8R, 9L      10, 8L, 9R       2022-09-01 11:48:13   \n",
      "20            8R, 9L      10, 8L, 9R       2022-09-01 11:58:11   \n",
      "21            8R, 9L      10, 8L, 9R       2022-09-01 12:15:47   \n",
      "22            8R, 9L      10, 8L, 9R       2022-09-01 12:53:12   \n",
      "23            8R, 9L      10, 8L, 9R       2022-09-01 13:52:57   \n",
      "24            8R, 9L      10, 8L, 9R       2022-09-01 14:54:27   \n",
      "25            8R, 9L      10, 8L, 9R       2022-09-01 15:53:03   \n",
      "26            8R, 9L      10, 8L, 9R       2022-09-01 16:53:25   \n",
      "27            8R, 9L      10, 8L, 9R       2022-09-01 17:53:45   \n",
      "28            8R, 9L      10, 8L, 9R       2022-09-01 18:53:11   \n",
      "29            8R, 9L      10, 8L, 9R       2022-09-01 19:53:19   \n",
      "30            8R, 9L      10, 8L, 9R       2022-09-01 20:52:51   \n",
      "31            8R, 9L      10, 8L, 9R       2022-09-01 21:54:45   \n",
      "32            8R, 9L      10, 8L, 9R       2022-09-01 22:53:10   \n",
      "33            8R, 9L      10, 8L, 9R       2022-09-01 23:52:53   \n",
      "\n",
      "   timestamp_source_processed  invalid_departure_runways  \\\n",
      "0         2022-09-01 00:52:51                        NaN   \n",
      "1         2022-09-01 01:53:12                        NaN   \n",
      "2         2022-09-01 02:06:05                        NaN   \n",
      "3         2022-09-01 02:54:44                        NaN   \n",
      "4         2022-09-01 03:32:39                        NaN   \n",
      "5         2022-09-01 04:04:59                        NaN   \n",
      "6         2022-09-01 04:06:20                        NaN   \n",
      "7         2022-09-01 04:54:30                        NaN   \n",
      "8         2022-09-01 06:06:50                        NaN   \n",
      "9         2022-09-01 06:53:05                        NaN   \n",
      "10        2022-09-01 07:56:17                        NaN   \n",
      "11        2022-09-01 08:15:53                        NaN   \n",
      "12        2022-09-01 09:08:44                        NaN   \n",
      "13        2022-09-01 09:38:21                        NaN   \n",
      "14        2022-09-01 09:43:51                        NaN   \n",
      "15        2022-09-01 09:54:52                        NaN   \n",
      "16        2022-09-01 10:03:39                        NaN   \n",
      "17        2022-09-01 10:18:30                        2.0   \n",
      "18        2022-09-01 10:55:26                        2.0   \n",
      "19        2022-09-01 11:48:13                        2.0   \n",
      "20        2022-09-01 11:58:11                        2.0   \n",
      "21        2022-09-01 12:15:47                        2.0   \n",
      "22        2022-09-01 12:53:12                        2.0   \n",
      "23        2022-09-01 13:52:57                        2.0   \n",
      "24        2022-09-01 14:54:27                        2.0   \n",
      "25        2022-09-01 15:53:03                        2.0   \n",
      "26        2022-09-01 16:53:25                        2.0   \n",
      "27        2022-09-01 17:53:45                        2.0   \n",
      "28        2022-09-01 18:53:11                        2.0   \n",
      "29        2022-09-01 19:53:19                        2.0   \n",
      "30        2022-09-01 20:52:51                        2.0   \n",
      "31        2022-09-01 21:54:45                        2.0   \n",
      "32        2022-09-01 22:53:10                        2.0   \n",
      "33        2022-09-01 23:52:53                        2.0   \n",
      "\n",
      "    invalid_arrival_runways  \\\n",
      "0                       NaN   \n",
      "1                       NaN   \n",
      "2                       NaN   \n",
      "3                       NaN   \n",
      "4                       NaN   \n",
      "5                       NaN   \n",
      "6                       NaN   \n",
      "7                       NaN   \n",
      "8                       NaN   \n",
      "9                       NaN   \n",
      "10                      NaN   \n",
      "11                      NaN   \n",
      "12                      NaN   \n",
      "13                      NaN   \n",
      "14                      NaN   \n",
      "15                      NaN   \n",
      "16                      NaN   \n",
      "17                      NaN   \n",
      "18                      NaN   \n",
      "19                      NaN   \n",
      "20                      NaN   \n",
      "21                      NaN   \n",
      "22                      NaN   \n",
      "23                      NaN   \n",
      "24                      NaN   \n",
      "25                      NaN   \n",
      "26                      NaN   \n",
      "27                      NaN   \n",
      "28                      NaN   \n",
      "29                      NaN   \n",
      "30                      NaN   \n",
      "31                      NaN   \n",
      "32                      NaN   \n",
      "33                      NaN   \n",
      "\n",
      "                              departure_runway_string  \\\n",
      "0   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT RNAV OF...   \n",
      "1   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT RNAV OF...   \n",
      "2   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT RNAV OF...   \n",
      "3   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT RNAV OF...   \n",
      "4   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "5   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "6   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "7   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "8   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "9   SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "10  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "11  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "12  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "13  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "14  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "15  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "16  SIMUL DEPS, DEPG RWYS, 26L, 27R. XPECT INITIAL...   \n",
      "17  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT INTIAL HE...   \n",
      "18  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "19  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "20  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "21  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "22  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "23  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "24  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "25  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "26  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "27  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "28  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "29  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "30  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "31  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "32  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "33  SIMUL DEPS, DEPG RWYS, 8R, 9L. XPECT RNAV OFF ...   \n",
      "\n",
      "                                arrival_runway_string  \\\n",
      "0   SIMULTANEOUS APCHS IN USE VIS 26R, ILS 27L, VI...   \n",
      "1   SIMULTANEOUS APCHS IN USE VIS 26R, ILS 27L, VI...   \n",
      "2   SIMULTANEOUS APCHS IN USE VIS 26R, ILS 27L, VI...   \n",
      "3   SIMULTANEOUS APCHS IN USE VIS 26R, ILS 27L, VI...   \n",
      "4   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "5   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "6   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "7   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "8   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "9   VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "10  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "11  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "12  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "13  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 27R.   \n",
      "14  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 2...   \n",
      "15  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 2...   \n",
      "16  VISUAL APPROACH RWY 26R, VISUAL APPROACH RWY 2...   \n",
      "17  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "18  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "19  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "20  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "21  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "22  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "23  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "24  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "25  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "26  SIMULTANEOUS APCHS IN USE VIS 8L, VIS 9R, VIS 10.   \n",
      "27  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "28  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "29  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "30  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "31  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "32  SIMULTANEOUS APCHS IN USE VIS 8L, ILS 9R, VIS 10.   \n",
      "33  SIMULTANEOUS APCHS IN USE ILS 8L, ILS 9R, VIS 10.   \n",
      "\n",
      "   airport_configuration_name file_type  \n",
      "0      D_26L_27R_A_26R_27L_28   configs  \n",
      "1      D_26L_27R_A_26R_27L_28   configs  \n",
      "2      D_26L_27R_A_26R_27L_28   configs  \n",
      "3      D_26L_27R_A_26R_27L_28   configs  \n",
      "4         D_26L_27R_A_26R_27R   configs  \n",
      "5         D_26L_27R_A_26R_27R   configs  \n",
      "6         D_26L_27R_A_26R_27R   configs  \n",
      "7         D_26L_27R_A_26R_27R   configs  \n",
      "8         D_26L_27R_A_26R_27R   configs  \n",
      "9         D_26L_27R_A_26R_27R   configs  \n",
      "10        D_26L_27R_A_26R_27R   configs  \n",
      "11        D_26L_27R_A_26R_27R   configs  \n",
      "12        D_26L_27R_A_26R_27R   configs  \n",
      "13        D_26L_27R_A_26R_27R   configs  \n",
      "14     D_26L_27R_A_26R_27L_28   configs  \n",
      "15     D_26L_27R_A_26R_27L_28   configs  \n",
      "16     D_26L_27R_A_26R_27L_28   configs  \n",
      "17         D_8R_9L_A_10_8L_9R   configs  \n",
      "18         D_8R_9L_A_10_8L_9R   configs  \n",
      "19         D_8R_9L_A_10_8L_9R   configs  \n",
      "20         D_8R_9L_A_10_8L_9R   configs  \n",
      "21         D_8R_9L_A_10_8L_9R   configs  \n",
      "22         D_8R_9L_A_10_8L_9R   configs  \n",
      "23         D_8R_9L_A_10_8L_9R   configs  \n",
      "24         D_8R_9L_A_10_8L_9R   configs  \n",
      "25         D_8R_9L_A_10_8L_9R   configs  \n",
      "26         D_8R_9L_A_10_8L_9R   configs  \n",
      "27         D_8R_9L_A_10_8L_9R   configs  \n",
      "28         D_8R_9L_A_10_8L_9R   configs  \n",
      "29         D_8R_9L_A_10_8L_9R   configs  \n",
      "30         D_8R_9L_A_10_8L_9R   configs  \n",
      "31         D_8R_9L_A_10_8L_9R   configs  \n",
      "32         D_8R_9L_A_10_8L_9R   configs  \n",
      "33         D_8R_9L_A_10_8L_9R   configs  \n"
     ]
    }
   ],
   "source": [
    "print(fuser_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metar_data = load_data(\n",
    "    data_type=\"METAR\", \n",
    "    dataset_purpose=\"test\",  \n",
    "    file_name=\"metar.20220925.00Z\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     station datetime  auto      wind visibility      clouds temperature  \\\n",
      "0       AGGH  250000Z  None   05010KT       9999  [FEW021CB]          31   \n",
      "1       AGGH  250000Z  None   05010KT       9999  [FEW021CB]          31   \n",
      "2       AGGH  250000Z  None   05010KT       9999  [FEW021CB]          31   \n",
      "3       AGGH  250000Z  None   05010KT       9999  [FEW021CB]          31   \n",
      "4       AYNZ  250000Z  None   29003KT       9999    [BKN090]          28   \n",
      "...      ...      ...   ...       ...        ...         ...         ...   \n",
      "4498    ZYTX  250000Z  None  17004MPS      CAVOK        None          18   \n",
      "4499    ZYTX  250000Z  None  17004MPS      CAVOK        None          18   \n",
      "4500    ZYTX  250030Z  None  18005MPS      CAVOK        None          19   \n",
      "4501    ZYTX  250030Z  None  18005MPS      CAVOK        None          19   \n",
      "4502    ZYTX  250030Z  None  18005MPS      CAVOK        None          19   \n",
      "\n",
      "     dewpoint pressure remarks         date_time  \n",
      "0          25     1011    None  2022/09/25 00:00  \n",
      "1          25     1011    None  2022/09/25 00:00  \n",
      "2          25     1011    None  2022/09/25 00:00  \n",
      "3          25     1011    None  2022/09/25 00:00  \n",
      "4          22     1012    None  2022/09/25 00:00  \n",
      "...       ...      ...     ...               ...  \n",
      "4498       11     1013   NOSIG  2022/09/25 00:00  \n",
      "4499       11     1013   NOSIG  2022/09/25 00:00  \n",
      "4500       11     1013   NOSIG  2022/09/25 00:30  \n",
      "4501       11     1013   NOSIG  2022/09/25 00:30  \n",
      "4502       11     1013   NOSIG  2022/09/25 00:30  \n",
      "\n",
      "[4503 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(metar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "taf_data = load_data( \n",
    "    data_type=\"TAF\", \n",
    "    dataset_purpose=\"test\",  \n",
    "    file_name=\"taf.20220925.00Z\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       station datetime   validity     wind visibility  clouds temp_dewpoint  \\\n",
      "0     TAF SMJP  242200Z  2500/2524  07005KT       9999  SCT025    TX34/2517Z   \n",
      "1     TAF SMZO  242200Z  2500/2524  06006KT       9999  SCT025    TX34/2517Z   \n",
      "2     TAF FACT  242200Z  2500/2606  VRB03KT      CAVOK    None    TX22/2513Z   \n",
      "3     TAF FAGG  242200Z  2500/2524  33005KT      CAVOK    None    TX21/2510Z   \n",
      "4     TAF FALE  242200Z  2500/2606  VRB03KT       9999  SCT015    TX34/2512Z   \n",
      "...        ...      ...        ...      ...        ...     ...           ...   \n",
      "7455  TAF FYWB  252200Z  2600/2700  05005KT       0700    None          None   \n",
      "7456  TAF FBSK  252200Z  2600/2706  04008KT      CAVOK    None          None   \n",
      "7457  TAF HDAM  252300Z  2600/2624  12010KT       8000    None          None   \n",
      "7458  TAF OPKC  252130Z  2600/2706  26010KT       6000    None          None   \n",
      "7459  TAF TNCM  252200Z  2600/2624  08010KT       9999  SCT018          None   \n",
      "\n",
      "     probability temporary becoming from_forecasts     Date and Time  \n",
      "0                                                   2022/09/24 00:00  \n",
      "1                                                   2022/09/24 00:00  \n",
      "2                                                   2022/09/24 00:00  \n",
      "3                                                   2022/09/24 00:00  \n",
      "4                                                   2022/09/24 00:00  \n",
      "...          ...       ...      ...            ...               ...  \n",
      "7455                                                2022/09/25 00:00  \n",
      "7456                                                2022/09/25 00:06  \n",
      "7457                                                2022/09/25 00:06  \n",
      "7458                                                2022/09/25 00:06  \n",
      "7459                                                2022/09/25 00:00  \n",
      "\n",
      "[7460 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(taf_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
